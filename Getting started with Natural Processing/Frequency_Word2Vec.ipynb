{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Frequency Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EDpRn3fu0SKY",
        "uoKVLvEW6gOV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QZT_AqTyGQj"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yejUHLNCSzt"
      },
      "source": [
        "Lets take an example of 5 sentences. We will first create vocabulary of the words and assign a number to each word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgOLMTfYyUQM"
      },
      "source": [
        "sent1 = \"He is playing in the field\".lower()\r\n",
        "sent2 = \"He is running around with his friends\".lower()\r\n",
        "sent3 = \"They are playing football\".lower()\r\n",
        "sent4 = \"It started raining while they were playing\".lower()\r\n",
        "sent5 = \"They stopped playing football and are now playing ludo\".lower()\r\n",
        "all_text = [sent1, sent2, sent3, sent4, sent5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4mcAshZyuNC"
      },
      "source": [
        "vocab_dict = Counter([x for sent in all_text for x in sent.split()])\r\n",
        "vocab = list(set([x for x in vocab_dict]))\r\n",
        "vocab_len = len(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwJIsY90CuAG",
        "outputId": "258394c0-8ef5-4cfc-a79b-ae527a07f43b"
      },
      "source": [
        "print(vocab)\r\n",
        "print(vocab_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['he', 'it', 'running', 'with', 'and', 'while', 'in', 'started', 'they', 'raining', 'ludo', 'field', 'are', 'stopped', 'playing', 'football', 'the', 'is', 'now', 'his', 'were', 'friends', 'around']\n",
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDpRn3fu0SKY"
      },
      "source": [
        "## Count Vectorizer\r\n",
        "Taking each sentence one at a time, we’ll read the first word, find it’s total occurrence in the sentence. Once we have the number of times it appears in that sentence, we’ll identify the position of the word in the list above and replace the same zero with this count at that position. This is repeated for all words and for all sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGtXYOUUzufI"
      },
      "source": [
        "def get_count_vectors():\r\n",
        "  all_vectors = [np.zeros(vocab_len) for sent in all_text]\r\n",
        "  for i, sent in enumerate(all_text):\r\n",
        "    sent_counter = Counter(sent.split())\r\n",
        "    for j, term in enumerate(vocab):\r\n",
        "      if term in sent_counter:\r\n",
        "        term_counter = sent_counter[term]\r\n",
        "      else:\r\n",
        "        term_counter = 0\r\n",
        "      all_vectors[i][j] = term_counter\r\n",
        "    return all_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyXcjLua4uzP",
        "outputId": "09612332-116c-4430-8633-90bb0a734d03"
      },
      "source": [
        "all_vectors = get_count_vectors()\r\n",
        "print(all_vectors)\r\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
            "       1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0.])]\n",
            "['he', 'it', 'running', 'with', 'and', 'while', 'in', 'started', 'they', 'raining', 'ludo', 'field', 'are', 'stopped', 'playing', 'football', 'the', 'is', 'now', 'his', 'were', 'friends', 'around']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVgLd0dc47vM"
      },
      "source": [
        "Creating Count Vectorizer Using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUV8eRx-zhLz"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "sentence_vectors = vectorizer.fit_transform(all_text)\r\n",
        "\r\n",
        "print(sentence_vectors.toarray())\r\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoKVLvEW6gOV"
      },
      "source": [
        "# TF-IDF\r\n",
        "\r\n",
        "TF (Term Frequency) — It is defined as the number of times a word appears in the given sentence.\r\n",
        "\r\n",
        "IDF (Inverse Document Frequency) — It is defined as the log to the base e of number of the total documents divided by the documents in which the word appears.\r\n",
        "\r\n",
        "For each word in each sentence, we’ll calculate the TF-IDF value and update the corresponding value in the vector of that sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "3x9RL-Qk5HfN",
        "outputId": "b60c3f41-9b0e-479c-abea-9f8196da7a1e"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "tfidfvectorizer = TfidfVectorizer()\r\n",
        "sentence_vectors = tfidfvectorizer.fit_transform(all_text)\r\n",
        "print(sentence_vectors.toarray())\r\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.46528078 0.         0.\n",
            "  0.3753856  0.         0.46528078 0.3753856  0.         0.\n",
            "  0.         0.26213107 0.         0.         0.         0.\n",
            "  0.46528078 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.39835162 0.         0.         0.39835162\n",
            "  0.32138758 0.39835162 0.         0.32138758 0.         0.\n",
            "  0.         0.         0.         0.39835162 0.         0.\n",
            "  0.         0.         0.         0.         0.39835162]\n",
            " [0.         0.56106597 0.         0.         0.56106597 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.39179133 0.         0.         0.         0.\n",
            "  0.         0.46573544 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.41645294 0.\n",
            "  0.         0.23462232 0.41645294 0.         0.41645294 0.\n",
            "  0.         0.27890339 0.41645294 0.41645294 0.        ]\n",
            " [0.37742714 0.30450584 0.         0.         0.30450584 0.\n",
            "  0.         0.         0.         0.         0.         0.37742714\n",
            "  0.37742714 0.42527174 0.         0.         0.         0.37742714\n",
            "  0.         0.25276736 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-78c13324fd34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msentence_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidfvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyAAbqBHU2Tu"
      },
      "source": [
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyV7DYKiUYMA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}